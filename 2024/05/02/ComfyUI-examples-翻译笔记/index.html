<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>ComfyUI_examples 翻译笔记 - 徐炜楠的个人网站</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="徐炜楠的个人网站"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="徐炜楠的个人网站"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="在学习 ComfyUI 的过程中直接把官方的 Examples 文档翻译完了。"><meta property="og:type" content="blog"><meta property="og:title" content="ComfyUI_examples 翻译笔记"><meta property="og:url" content="http://xuweinan.com/2024/05/02/ComfyUI-examples-%E7%BF%BB%E8%AF%91%E7%AC%94%E8%AE%B0/"><meta property="og:site_name" content="徐炜楠的个人网站"><meta property="og:description" content="在学习 ComfyUI 的过程中直接把官方的 Examples 文档翻译完了。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/hiresfix_latent_workflow.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/hiresfix_esrgan_workflow.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/latent_upscale_different_prompt_model.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/img2img/img2img_workflow.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpaint_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/yosemite_inpaint_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpain_model_cat.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpain_model_woman.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpaint_anythingv3_woman.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/yosemite_outpaint_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpain_model_outpainting.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/lora/lora.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/lora/lora_multiple.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/hypernetwork_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/textual_inversion_embeddings/embedding_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/esrgan_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/night_evening_day_morning.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/workflow_night_evening_day_morning.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/morning_day_evening_night.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/night_evening_day_morning_subject.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/square_area_for_subject.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/square_area_for_2_subjects_first_pass.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/square_area_for_2_subjects.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/noisy_latent_composition/noisy_latents_3_subjects.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/noisy_latent_composition/noisy_latents_3_subjects_.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/controlnet_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/input_scribble_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/shark_depthmap.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/depth_t2i_adapter.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/depth_controlnet.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/pose_worship.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/2_pass_pose_worship.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/mixing_controlnets.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/pose_present.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/house_scribble.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/gligen/gligen_textbox_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/unclip/unclip_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/unclip/unclip_example_multiple.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/unclip/mountains.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/unclip/sunset.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/unclip/unclip_2pass.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_simple_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_refiner_prompt_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_revision_zero_positive.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_revision_text_prompts.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/unclip/mountains.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/unclip/sunset.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_basic.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_3_checkpoints.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_lora.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_inpaint.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_cosxl.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/3d/stable_zero123_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/lcm/lcm_basic_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/sdxlturbo_example.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__text_to_image.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__image_to_image.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__image_remixing.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__image_remixing_multiple.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__canny_controlnet.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__inpaint_controlnet.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/edit_models/sdxl_edit_model.png"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/video/image_to_video.webp"><meta property="og:image" content="https://comfyanonymous.github.io/ComfyUI_examples/video/txt_to_image_to_video.webp"><meta property="article:published_time" content="2024-05-02T03:32:42.000Z"><meta property="article:modified_time" content="2024-05-02T03:33:49.178Z"><meta property="article:author" content="徐炜楠"><meta property="article:tag" content="随笔"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/hiresfix_latent_workflow.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://xuweinan.com/2024/05/02/ComfyUI-examples-%E7%BF%BB%E8%AF%91%E7%AC%94%E8%AE%B0/"},"headline":"ComfyUI_examples 翻译笔记","image":["https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/hiresfix_latent_workflow.png","https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/hiresfix_esrgan_workflow.png","https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/latent_upscale_different_prompt_model.png","https://comfyanonymous.github.io/ComfyUI_examples/img2img/img2img_workflow.png","https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpaint_example.png","https://comfyanonymous.github.io/ComfyUI_examples/inpaint/yosemite_inpaint_example.png","https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpain_model_cat.png","https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpain_model_woman.png","https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpaint_anythingv3_woman.png","https://comfyanonymous.github.io/ComfyUI_examples/inpaint/yosemite_outpaint_example.png","https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpain_model_outpainting.png","https://comfyanonymous.github.io/ComfyUI_examples/lora/lora.png","https://comfyanonymous.github.io/ComfyUI_examples/lora/lora_multiple.png","https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/hypernetwork_example.png","https://comfyanonymous.github.io/ComfyUI_examples/textual_inversion_embeddings/embedding_example.png","https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/esrgan_example.png","https://comfyanonymous.github.io/ComfyUI_examples/area_composition/night_evening_day_morning.png","https://comfyanonymous.github.io/ComfyUI_examples/area_composition/workflow_night_evening_day_morning.png","https://comfyanonymous.github.io/ComfyUI_examples/area_composition/morning_day_evening_night.png","https://comfyanonymous.github.io/ComfyUI_examples/area_composition/night_evening_day_morning_subject.png","https://comfyanonymous.github.io/ComfyUI_examples/area_composition/square_area_for_subject.png","https://comfyanonymous.github.io/ComfyUI_examples/area_composition/square_area_for_2_subjects_first_pass.png","https://comfyanonymous.github.io/ComfyUI_examples/area_composition/square_area_for_2_subjects.png","https://comfyanonymous.github.io/ComfyUI_examples/noisy_latent_composition/noisy_latents_3_subjects.png","https://comfyanonymous.github.io/ComfyUI_examples/noisy_latent_composition/noisy_latents_3_subjects_.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/controlnet_example.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/input_scribble_example.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/shark_depthmap.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/depth_t2i_adapter.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/depth_controlnet.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/pose_worship.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/2_pass_pose_worship.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/mixing_controlnets.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/pose_present.png","https://comfyanonymous.github.io/ComfyUI_examples/controlnet/house_scribble.png","https://comfyanonymous.github.io/ComfyUI_examples/gligen/gligen_textbox_example.png","https://comfyanonymous.github.io/ComfyUI_examples/unclip/unclip_example.png","https://comfyanonymous.github.io/ComfyUI_examples/unclip/unclip_example_multiple.png","https://comfyanonymous.github.io/ComfyUI_examples/unclip/mountains.png","https://comfyanonymous.github.io/ComfyUI_examples/unclip/sunset.png","https://comfyanonymous.github.io/ComfyUI_examples/unclip/unclip_2pass.png","https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_simple_example.png","https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_refiner_prompt_example.png","https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_revision_zero_positive.png","https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_revision_text_prompts.png","https://comfyanonymous.github.io/ComfyUI_examples/unclip/mountains.png","https://comfyanonymous.github.io/ComfyUI_examples/unclip/sunset.png","https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_basic.png","https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_3_checkpoints.png","https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_lora.png","https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_inpaint.png","https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_cosxl.png","https://comfyanonymous.github.io/ComfyUI_examples/3d/stable_zero123_example.png","https://comfyanonymous.github.io/ComfyUI_examples/lcm/lcm_basic_example.png","https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/sdxlturbo_example.png","https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__text_to_image.png","https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__image_to_image.png","https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__image_remixing.png","https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__image_remixing_multiple.png","https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__canny_controlnet.png","https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__inpaint_controlnet.png","https://comfyanonymous.github.io/ComfyUI_examples/edit_models/sdxl_edit_model.png","https://comfyanonymous.github.io/ComfyUI_examples/video/image_to_video.webp","https://comfyanonymous.github.io/ComfyUI_examples/video/txt_to_image_to_video.webp"],"datePublished":"2024-05-02T03:32:42.000Z","dateModified":"2024-05-02T03:33:49.178Z","author":{"@type":"Person","name":"徐炜楠"},"publisher":{"@type":"Organization","name":"徐炜楠的个人网站","logo":{"@type":"ImageObject","url":{"text":"XUWEINAN"}}},"description":"在学习 ComfyUI 的过程中直接把官方的 Examples 文档翻译完了。"}</script><link rel="canonical" href="http://xuweinan.com/2024/05/02/ComfyUI-examples-%E7%BF%BB%E8%AF%91%E7%AC%94%E8%AE%B0/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.2"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">XUWEINAN</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-05-02T03:32:42.000Z" title="2024-05-02, 11:32:42 a.m.">2024-05-02</time>发表</span><span class="level-item"> 徐炜楠 </span><span class="level-item"><a class="link-muted" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></span><span class="level-item">1 小时读完 (大约7970个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">ComfyUI_examples 翻译笔记</h1><div class="content"><p>在学习 ComfyUI 的过程中直接把官方的 Examples 文档翻译完了。</p>
<span id="more"></span>

<h2 id="1-2-Pass-Txt2Img-Hires-fix-Examples"><a href="#1-2-Pass-Txt2Img-Hires-fix-Examples" class="headerlink" title="1. 2 Pass Txt2Img (Hires fix) Examples"></a>1. 2 Pass Txt2Img (Hires fix) Examples</h2><p>这里是一些示例，向你展示应该如何实现“Hires Fix”（高清修复）这个功能。</p>
<blockquote>
<p><strong>GPT 解释 Hires Fix</strong>：<br>“Hires fix” 或者又称为高分辨率修复，是一种在深度学习和图像生成领域中用来提高图像分辨率和细节的技术。</p>
<p><strong>GPT 解释 2 pass workflow：</strong><br>在软件开发和界面设计中，”2 pass workflow” 或 “two-pass workflow” 是指一个过程或任务在完成时需要两个阶段或步骤。具体到 ComfyUI 或类似的界面框架中，这通常涉及到两个主要的过程：</p>
<p>第一遍（First Pass）：在这一阶段，系统会进行初步的处理，例如收集数据、进行初步计算或者确定哪些元素需要在界面上展示。这一步骤通常是准备阶段，为第二遍处理做好铺垫。<br>第二遍（Second Pass）：在第一遍处理之后，第二遍通常涉及更细致或针对性的处理。例如，在界面布局中，第一遍可能确定了哪些组件需要显示，而第二遍则可能涉及到具体的布局计算，如组件的位置和大小调整，以确保最佳的用户体验。<br>在界面设计和开发中，两遍工作流可以帮助开发者更高效地处理和渲染界面，尤其是在需要处理大量数据或复杂交互时。通过将处理过程分解为两个阶段，可以优化性能和响应速度，同时降低错误和问题的风险。</p>
</blockquote>
<p>你可以直接把这些图片拖动到 ComfyUI 中来观察完整的 workflow。</p>
<p>Hires fix 是先创建了一张低清晰度的图片，然后通过 img2img 来放大它。请注意，在 ComfyUI 中 txt2img 和 img2img 是一样的节点。Txt2img 节点是通过传入一张负有最大噪点的空图片给采样器节点来实现的。</p>
<p>以下是一个简单的 ComfyUI workflow，可以实现基础的 latent（潜在空间）放大：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/hiresfix_latent_workflow.png" alt="Example"></p>
<h3 id="非-latent-放大"><a href="#非-latent-放大" class="headerlink" title="非 latent 放大"></a>非 latent 放大</h3><p>这里是一个在放大步骤中使用了 ESRGAN 放大器的例子，因为ESRGAN 是直接在 pixel space（像素空间）中运行的，所以，图片必须转换成像素控件然后放大后再返回到 latent space（潜在空间）。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/hiresfix_esrgan_workflow.png" alt="Example"></p>
<blockquote>
<p><strong>译者：</strong></p>
<p>这里用到一个 <a target="_blank" rel="noopener" href="https://huggingface.co/lllyasviel/Annotators/blob/main/RealESRGAN_x4plus.pth">RealESRGAN_x4plus.pth</a> 模型需要下载。</p>
</blockquote>
<h3 id="更多示例"><a href="#更多示例" class="headerlink" title="更多示例"></a>更多示例</h3><p>这里是一个更加复杂的 2 pass workflow （两道工序工作流），这张图是先从 WD1.5 beta 3 illusion 模型生成，然后通过 latent 放大方式放大，之后再传给 cardosAnime_v10 处理。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/latent_upscale_different_prompt_model.png" alt="Example"></p>
<blockquote>
<p><strong>译者：</strong></p>
<p>“CLIP Set Last Layer”节点可以用来设置CLIP模型中从哪一个输出层获取文本嵌入。文本转换为嵌入是通过文本在CLIP模型的各个层中被转换实现的。虽然传统上扩散模型是基于CLIP中最后一层的输出进行条件化的，但一些扩散模型已经基于较早的层进行了条件化，并且在使用最后一层的输出时可能不会工作得那么好。</p>
</blockquote>
<h2 id="2-Img2Img-Examples"><a href="#2-Img2Img-Examples" class="headerlink" title="2.  Img2Img Examples"></a>2.  Img2Img Examples</h2><p>这里是一个展示如何实现 img2img 的例子。</p>
<p>你可以直接把这些图片拖动到 ComfyUI 中来观察完整的 workflow。</p>
<p>Img2Img 需要先加载一张图片来工作，先将它通过 VAE 转换为 latent space，然后用低于 1.0 的 denoise 进行采样。denoise 控制的是添加到图片的噪点数量，噪点添加的越少，图片改变的越少。</p>
<p>输入图片需要被放置在 input 文件夹中。</p>
<p>一个简单的 img2img 看起来长下面这样，和默认的 txt2img 流程很像，不过 denoise 被设置在了 0.87，也传了一张真实的图片而非空图片给 KSampler。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/img2img/img2img_workflow.png" alt="Example"></p>
<h2 id="3-Inpaint-Examples"><a href="#3-Inpaint-Examples" class="headerlink" title="3. Inpaint Examples"></a>3. Inpaint Examples</h2><p><img src="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpaint_example.png"></p>
<p>在这个例子中，我们使用这张图片。下载并将其放置在输入文件夹中</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/yosemite_inpaint_example.png"></p>
<p>这张图片有一部分是通过 gimp （GNU Image Manipulation Program）擦除了一部分。alpha 通道将用做修复的蒙版。如果你也是用 GIMP，请确保你保存了透明像素的值，以便获取最佳的效果。<br>ComfyUI  也有一个蒙版编辑器，可以通过在 Load Image 图片中右键图片然后点击“Open in MaskEditor”来使用。<br>可以直接把下面的图片加载到 ComfyUI 中来查看完整的 workflow 。<br>使用 v2 Inpainting 模型在图像上修补一只猫。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpain_model_cat.png"></p>
<p>修补一个女人</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpain_model_woman.png"></p>
<p>如果不是专门的 inpainting 模型也可以用。这里就是一个例子，用的是 anythingV3 model：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpaint_anythingv3_woman.png"></p>
<h3 id="Outpainting"><a href="#Outpainting" class="headerlink" title="Outpainting"></a>Outpainting</h3><p>你也可以使用相似的 workflow 来实现 outpainting 功能。Outpainting 和 inpainting 是一样的，这里有一个“Pad Image for Outpainting”节点，可以根据合适的蒙版自动填补图像来进行 outpainting。在下面的这个例子中，这个图像将会被 outpainted:</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/yosemite_outpaint_example.png"></p>
<p>使用 v2 inpainting 模型和 “Pad Image for Outpainting” 节点（把它加载到 ComfyUI 中来看完整的 workflow ）：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/inpain_model_outpainting.png"></p>
<h2 id="4-Lora-Examples"><a href="#4-Lora-Examples" class="headerlink" title="4. Lora Examples"></a>4. Lora Examples</h2><p>这里是一些关于你应该如何去使用 Lora 的例子。所有类型的 LoRA 都可以使用这个方式，比如 Lycoris，loha，lokr，locon 等等。</p>
<p>你可以把这些图片加载到 ComfyUI 中来获得完整的 workflow 。</p>
<p>Lora 好比一个补丁，作用在主模型和 CLIP 模型上，所以为了使用 Lora，你需要把它放在 models/loras 目录下，然后在 ComfyUI 中使用 LoraLoader，就像这样：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/lora/lora.png" alt="Example"></p>
<p>你可以通过串联多个 LoraLoader 的方式使用多个 Lora ，就像这样：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/lora/lora_multiple.png" alt="Example"></p>
<h2 id="5-Hypernetwork-Examples"><a href="#5-Hypernetwork-Examples" class="headerlink" title="5. Hypernetwork Examples"></a>5. Hypernetwork Examples</h2><p>你可以把这些图片加载到 ComfyUI 中来获得完整的 workflow 。</p>
<p>Hypernetwork 是一个作用在主模型上的补丁，你需要把它放在 models/hypernetworks 目录下，然后在 ComfyUI 中使用 Hypernetwork Loader，就像这样：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/hypernetwork_example.png" alt="Example"></p>
<p>你可以通过串联多个 Hypernetwork Loader 的方式使用多个 hypernetwork。</p>
<h2 id="6-Textual-Inversion-Embeddings-Examples"><a href="#6-Textual-Inversion-Embeddings-Examples" class="headerlink" title="6. Textual Inversion Embeddings Examples"></a>6. Textual Inversion Embeddings Examples</h2><p>这是一个展示如何使用 Textual Inversion/Embeddings 的例子。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/textual_inversion_embeddings/embedding_example.png" alt="Example"></p>
<p>为了使用一个 embedding，你需要先将文件放在 models/embeddings 文件夹下，然后在你的 prompt 中使用，就像我在上图中使用 SDA768.pt 一样。</p>
<p>需要注意，你可以省略文件的后缀名，下面两种书写方式都是一样的：</p>
<p><code>embedding: SDA768.pt</code></p>
<p><code>embedding:SDA768</code></p>
<p>和其他 prompt 一样，你也可以设置 embedding 的强度：</p>
<p><code>(embedding:SDA768:1.2)</code></p>
<p>Embeddings 本质上就是一些自定义的词，所以在 prompt 中放置的位置很重要。</p>
<p>比如，如果你这样使用关于猫的一个 embedding：</p>
<p><code>red embedding:cat</code></p>
<p>这样大概率会给你一只红色的猫。</p>
<h2 id="7-Upscale-Model-Examples"><a href="#7-Upscale-Model-Examples" class="headerlink" title="7. Upscale Model Examples"></a>7. Upscale Model Examples</h2><p>这是一个教你如何用 upscale model（放大模型），比如 ESRGAN，的例子，把它们放在 models/upscale_models 文件夹下，然后使用 UpscaleModelLoader 节点来加载，并通过 ImageUpscaleWithModel 节点来使用。</p>
<p>这里是一个例子：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/esrgan_example.png" alt="Example"></p>
<p>你可以把这张图片加载到 ComfyUI 中来查看完整的 workflow 。</p>
<p>如果你在找一些可用的 upscale model，你可以访问 <a target="_blank" rel="noopener" href="https://openmodeldb.info/">OpenModelDB</a> 。</p>
<blockquote>
<p><strong>GPT 回答 Upscale Model 和 Hires fix 在放大图片上有什么不同:</strong></p>
<p>Stable Diffusion的Upscale Model和Hires fix都是用于提高图像分辨率和细节的工具，但它们在处理方式和细节增强上有所不同：</p>
<p>Upscale Model：<br>这种模型通常用于将图像的分辨率从较低的分辨率放大到更高的分辨率。<br>它通过添加更多的像素点来增加图像的总体尺寸，同时尽量保持图像内容的真实性和质量。<br>Upscale Model主要关注于图像尺寸的增加，适合于需要在不丢失过多细节的情况下查看更大版本图像的场景。<br>Hires Fix：<br>Hires fix更专注于在高分辨率图像生成时改善和修复细节。<br>它通常用于已经是高分辨率的图像，但可能在某些细节上不够清晰或存在一些视觉瑕疵。<br>Hires fix努力在保持高分辨率的同时提升图像质量，改进图像的局部细节，使其更加锐利和准确。<br>总的来说，如果你需要从较小的图像创建一个更大但保持质量的版本，Upscale Model是合适的选择。而如果你的图像已经具备较高分辨率，但需要在细节上进行改进或修复，Hires fix可能是更好的选择。</p>
</blockquote>
<h2 id="8-Area-Composition-Examples"><a href="#8-Area-Composition-Examples" class="headerlink" title="8. Area Composition Examples"></a>8. Area Composition Examples</h2><p>这里是一些教你如何使用 ConditioningSetArea 节点的例子。你可以把这些图片拖动到 ComfyUI 中来查看完整的 workflow 。</p>
<h3 id="Area-composition-with-Anything-V3-second-pass-with-AbyssOrangeMix2-hard"><a href="#Area-composition-with-Anything-V3-second-pass-with-AbyssOrangeMix2-hard" class="headerlink" title="Area composition with Anything-V3 + second pass with AbyssOrangeMix2_hard"></a>Area composition with Anything-V3 + second pass with AbyssOrangeMix2_hard</h3><p>这张图片包含了4个不同的区域，夜晚、晚上、白天、早晨。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/night_evening_day_morning.png" alt="Example"></p>
<p>workflow 看起来是这样的：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/workflow_night_evening_day_morning.png" alt="Example"></p>
<p>这张图片也是同样的四个区域，不过顺序反了一下：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/morning_day_evening_night.png" alt="Example"></p>
<p>然后通过添加另一个区域 prompt ，可以在图片中心靠下的位置添加一个主体。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/night_evening_day_morning_subject.png" alt="Example"></p>
<h3 id="Increasing-Consistency-of-images-with-Area-Composition"><a href="#Increasing-Consistency-of-images-with-Area-Composition" class="headerlink" title="Increasing Consistency of images with Area Composition"></a>Increasing Consistency of images with Area Composition</h3><p>Stable Diffusion 在生成接近512x512分辨率的正方形图像时，能够创造出最 consistent （一致） 的图像效果。但是如果我们想生成一张 16:9 比例的图像呢？让我们生成一张带有坐姿的 16:9 的图片吧。如果正常生成，成功率会很低，因为肢体会在图像上不自然的延伸，可能还会有其他的 consistent 问题。</p>
<p>通过使用 Area Composition 方法，给主体划定一个正方形区域，consistency 会更加高，因为它和图像的其余部分是同时生成的，最后整体图像的效果会更好。</p>
<p>下面这个 workflow 用了 Anything-V3 模型，还用了带有 area composition 的 2 pass workflow，area composition 被用在第一道工序中，用来生成图像左侧的主体。第二道则只是为了提高分辨率，如果你觉得 1280×704 分辨率 OK 的话你也可以跳过第二道。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/square_area_for_subject.png" alt="Example"></p>
<p>使用区域 prompt 在图片的右边添加了一个红色头发的主体。</p>
<p>第一道输出（1280×704）：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/square_area_for_2_subjects_first_pass.png" alt="Example"></p>
<p>第二道输出（1920×1080）：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/area_composition/square_area_for_2_subjects.png" alt="Example"></p>
<p>第二道输出的图像展示了 Stable Diffusion 生成的一种特点。第二遍处理时没有区域提示。很容易注意到，左边主体的头发是金色的，但是带有粉红色的光泽，第二位主体的头发是粉红色的，而第一道输出的图片则是深红。这是因为 Stable Diffsuion 试图将整个图像保持一致性，其副作用之一就是将头发颜色融合在一起。</p>
<h2 id="9-Noisy-Latent-Composition-Examples"><a href="#9-Noisy-Latent-Composition-Examples" class="headerlink" title="9. Noisy Latent Composition Examples"></a>9. Noisy Latent Composition Examples</h2><p>你可以把这些图片拖动到 ComfyUI 中来查看完整的 workflow 。</p>
<p>这里是一些 Noisy Latent Composition 的例子。Noisy Latent Composition 指的是，在图像完全去噪之前，在 latent 中，还带有噪点时进行合成。因为通常的形状比如 pose 和主体是在第一个采样步骤中被降噪，因此我们可以把一些特定 pose 的主体放置在图像中的任意位置，同时保持一定的 consistency。</p>
<p>这里是一个例子，这个例子把四张图融合到一起，一个背景和 3 个主体。总采样步数是 16。在 latent ，每种 prompt 都进行了 4 的采样。背景的分辨率是 1920×1088，主体每个都是 384×768。在这 4 步采样完成后，这些图片还是充满了噪点，然后这 3 个主体在适当羽化的条件下，被合成到了背景上。剩余的采样步骤（12 步）在合成后的图片上跑完。</p>
<p>下面这些例子是通过 WD1.5 beta 3 illusion 模型生成的。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/noisy_latent_composition/noisy_latents_3_subjects.png" alt="Example"></p>
<p>然后改变了主体的位置：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/noisy_latent_composition/noisy_latents_3_subjects_.png" alt="Example"></p>
<p>可以看到，由带噪点的不同 latent 图片组成的主体之间，还是相互作用的，因为我在提示中添加了“holding hands”。也很容易注意到背景的 consistent 非常强，也说明了这个方法很强大。</p>
<p>这个技术还有一些限制，它无法控制主体的细节，比如眼睛的颜色。但是它似乎在主体的位置、姿势和总体颜色控制上表现地非常好。</p>
<h2 id="10-ControlNet-and-T2I-Adapter-Examples"><a href="#10-ControlNet-and-T2I-Adapter-Examples" class="headerlink" title="10. ControlNet and T2I-Adapter Examples"></a>10. ControlNet and T2I-Adapter Examples</h2><p>请注意，在下面的例子中，原始图片都是直接从 ControlNet/T2I adapter 传过来的。</p>
<p>如果你想要产出好的结果，那需要给 ControlNet/T2I adapter 传入符合特定样式的图片，比如 depthmaps（深度图）、canny maps 边缘图等，具体格式取决于你使用的模型。</p>
<p>ControlNetApply 节点不会将常规图片转换成 depthmaps、canny maps 等特定样式的图片。你需要使用<a target="_blank" rel="noopener" href="https://github.com/Fannovel16/comfy_controlnet_preprocessors">一些节点</a>来预先处理这些图片。</p>
<p>你可以在<a target="_blank" rel="noopener" href="https://huggingface.co/lllyasviel/ControlNet-v1-1/tree/main">这里</a>找到最新的 controlnet 模型，或是它的 <a target="_blank" rel="noopener" href="https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/tree/main">fp16 小模型版本</a>。</p>
<p>对于 SDXL 模型，stability.ai 放出了 Controls Loras 的 <a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/control-lora/tree/main/control-LoRAs-rank256">rank 256</a> 和 <a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/control-lora/tree/main/control-LoRAs-rank128">rank 128</a> 版本，他们用起来就和普通的 ControlNet 模型文件一样。</p>
<p>ControlNet 的模型文件要放在 ComfyUI/models/controlnet 下。</p>
<h3 id="Scribble-ControlNet"><a href="#Scribble-ControlNet" class="headerlink" title="Scribble ControlNet"></a>Scribble ControlNet</h3><p>关于如何使用 ControlNet 这里有一个简单的例子，用了 Scribble ControlNet 和 AnythingV3 模型。你可以把这张图加载到 ComfyUI 中来查看玩着的 workflow。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/controlnet_example.png" alt="Example"></p>
<p>这张就是我在 workflow 中用到的输入图片：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/input_scribble_example.png" alt="img"></p>
<h3 id="T2I-Adapter-vs-ControlNets"><a href="#T2I-Adapter-vs-ControlNets" class="headerlink" title="T2I-Adapter vs ControlNets"></a>T2I-Adapter vs ControlNets</h3><p>我强烈推荐 T2I-Adapter ，它比 ControlNet 更加高效。使用 ControlNet 会显著降低图片生成的速度，而 T2I-Adapter 几乎对生成速度没有负面的影响。</p>
<p>ControlNet model 会在每轮 iteration（迭代）中都运行。而 T2I-Adapter 则之后运行一次。</p>
<p>在 ComfyUI 中 T2I-Adapter 的用法和 ControlNet 的用法一样，都是用 ControlNetLoader 节点。</p>
<p>这个是我在接下来的示例中会用到的图片，<a target="_blank" rel="noopener" href="https://commons.wikimedia.org/wiki/File:Stereogram_Tut_Shark_Depthmap.png">源地址</a></p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/shark_depthmap.png" alt="img"></p>
<p>然后这是完整的 workflow：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/depth_t2i_adapter.png" alt="Example"></p>
<p>接下来是 Controlnet 深度模型的用法。需要注意的是，这个例子用了 DiffControlNetLoader 因为 controlnet 模型用的是一个 diff 模型（注意文件名称）。Diff controlnet 需要模型的权重被加载正确。DiffControlNetLoader 节点也可以被用在常规的 controlnet 上面，当加载一个常规的 controlnet 模型的时候，就和 ControlNetLoader 节点一样了。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/depth_controlnet.png" alt="Example"></p>
<p>你可以直接把这些图片拖动到 ComfyUI 中来观察完整的 workflow。</p>
<h3 id="Pose-ControlNet"><a href="#Pose-ControlNet" class="headerlink" title="Pose ControlNet"></a>Pose ControlNet</h3><p>这是我会在接下来的例子中用到的输入图片：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/pose_worship.png" alt="Example"></p>
<p>这里是一个例子，第一道工序用了 AnythingV3 加上 controlnet，第二道是没有用 controlnet，直接用 AOM3A3(abuss orange mix 3)。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/2_pass_pose_worship.png" alt="Example"></p>
<p>你可以直接把这张图片拖动到 ComfyUI 中来观察完整的 workflow。</p>
<h3 id="Mixing-ControlNets"><a href="#Mixing-ControlNets" class="headerlink" title="Mixing ControlNets"></a>Mixing ControlNets</h3><p>多个 ControlNet 和 T2I-Adapters 可以像下图一样一起用，会产生有趣的结果。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/mixing_controlnets.png" alt="Example"></p>
<p>输入图片：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/pose_present.png" alt="img"></p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/controlnet/house_scribble.png" alt="img"></p>
<h2 id="11-GLIGEN-Examples"><a href="#11-GLIGEN-Examples" class="headerlink" title="11. GLIGEN Examples"></a>11. GLIGEN Examples</h2><p>可以在这里下载<a target="_blank" rel="noopener" href="https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/tree/main">受支持的 GLIGEN 模型文件的精简版本</a></p>
<p>把 GLIGEN 模型文件放在 ComfyUI/models/gligen 目录下。</p>
<h3 id="Text-box-GLIGEN"><a href="#Text-box-GLIGEN" class="headerlink" title="Text box GLIGEN"></a>Text box GLIGEN</h3><p>text box GLIGEN 模型让你可以指定图像中多个物体的位置和大小。想要正确的使用它，你先正常的写 prompt，然后用 GLIGEN Textbox Apply 节点来指定 prompt 中特定的物体或概念的位置和尺寸。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/gligen/gligen_textbox_example.png" alt="Example"></p>
<p>你可以直接把这张图片拖动到 ComfyUI 中来观察完整的 workflow。</p>
<h2 id="12-unCLIP-Model-Examples"><a href="#12-unCLIP-Model-Examples" class="headerlink" title="12. unCLIP Model Examples"></a>12. unCLIP Model Examples</h2><p>unCLIP 模型是 SD 模型的一种，它被特殊微调过，在文本 prompt 之外，还接受一个图像概念作为输入。图像通过这些模型附带的 CLIPVision 进行编码，然后在抽样的时候，将图像中被提取出来的概念传给主模型。</p>
<p>通俗一点说就是可以在 prompt 中用图像了。</p>
<p>这里是你如何在 ComfyUI 中使用它（还是一样的可以直接拖到 ComfyUI 中查看完整的 workflow）</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/unclip/unclip_example.png" alt="unclip_example"></p>
<p>noise_augmentation 参数控制着 unCLIP 模型尝试接近图片概念的程度。参数值越低越接近。</p>
<p>strength 是控制它影响图片的程度。</p>
<p>多个图片可以像这样被一起使用：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/unclip/unclip_example_multiple.png" alt="Example"></p>
<p>你会注意到它没有用传统的方式将图像直接融合在一起，而是从两者中挑选了一些概念，来创造出一张连贯的图像。</p>
<p>输入图片：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/unclip/mountains.png" alt="img"></p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/unclip/sunset.png" alt="img"></p>
<p>你可以在<a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-diffusion-2-1-unclip/tree/main">这里</a>下载官方的 unCLIP 模型。</p>
<p>你可以在<a target="_blank" rel="noopener" href="https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/tree/main">这里</a>（基于 WD1.5 beta 2）和<a target="_blank" rel="noopener" href="https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/tree/main">这里</a>（基于 Illuminati Diffusion）找到我根据一些现有 768-v 检查点制作的一些 unCLIP 检查点，我还做了一些巧妙的合并。</p>
<h3 id="More-advanced-Workflows"><a href="#More-advanced-Workflows" class="headerlink" title="More advanced Workflows"></a>More advanced Workflows</h3><p>一个使用 unCLIP 模型的好方法是，在 2 pass workflow 中，在第一道工序中使用 unCLIP 模型，然后在第二道工序中使用 1.x 的模型。下面这张图就是这么生成的。（可以在 ComfyUI 中加载来查看完整的 workflow）</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/unclip/unclip_2pass.png" alt="Example"></p>
<blockquote>
<p><strong>译者：</strong></p>
<p>我猜测是和 Midjourney 的垫图类似，通过先给定一些图片来确定风格，然后再通过 prompt 进行进一步的图片生成。</p>
</blockquote>
<h2 id="13-SDXL-Examples"><a href="#13-SDXL-Examples" class="headerlink" title="13. SDXL Examples"></a>13. SDXL Examples</h2><p>SDXL 模型的用法和常规模型的用法是一样的。不过为了获得更好的表现，应该把生成图像的分辨率设置成 1024×1024，或者其他的有着差不多总像素数量的分辨率，比如896×1152或1536×640都不错。</p>
<p>如果要把 base 模型和 refiner 模型一起用，你可以采用这样的 workflow。你可以下载并把这张图拖到 ComfyUI 中来查看完整的 workflow。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_simple_example.png" alt="Example"></p>
<p>你也可以在 base 模型和 refiner 模型上使用不同的 prompt。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_refiner_prompt_example.png" alt="Example"></p>
<h3 id="ReVision"><a href="#ReVision" class="headerlink" title="ReVision"></a>ReVision</h3><p>ReVision 和 unCLIP 很像，但是是在更加“概念化”的层面上工作，你可以传递一张或者多张图片给它，它会从这些图片中提取概念，并使用这些概念作为灵感创造图片。</p>
<p>首先下载 <a target="_blank" rel="noopener" href="https://huggingface.co/comfyanonymous/clip_vision_g/blob/main/clip_vision_g.safetensors">CLIP-G Vison</a> 然后把它放在 ComfyUI/models/clip_vision/ 目录下。</p>
<p>这里是一个示例的 workflow，可以被拖或加载到 ComfyUI 中。在这个例子中，为了能让最终输出尽可能的和输入的接近，text prompt 被 Zero Out （清空）了。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_revision_zero_positive.png" alt="Example"></p>
<p>如果你想使用 text prompt 你可以用这个：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/sdxl/sdxl_revision_text_prompts.png" alt="Example"></p>
<p>请注意，strength 选项可以用来调整每张输入图像对最终输出的影响。它也可以用在任意数量的图片上，不管是用单一的 unCLIPConditioning 节点还是像上面那样串联起多个节点。</p>
<p>以防万一你需要，这里是用来输入的图片。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/unclip/mountains.png" alt="img"></p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/unclip/sunset.png" alt="img"></p>
<h2 id="14-Model-Merging-Examples"><a href="#14-Model-Merging-Examples" class="headerlink" title="14. Model Merging Examples"></a>14. Model Merging Examples</h2><p>这些 workflow 背后的想法是，你可以进行一些包含了多个模型合并的复杂的 workflow，对其进行测试，然后一旦你觉得结果满意了，你可以通过启用 CheckpointSave 节点来保存这些 checkpoints（模型的一种）。</p>
<p>你可以在 advanced -&gt; model_merging 这个目录下找到这些节点。</p>
<p>第一个例子是一个基础例子，两个不同模型的简单合并。</p>
<p>你可以通过在 ComfyUI 中加载这些图片来查看完整的 workflow。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_basic.png" alt="Example"></p>
<p>在ComfyUI中，保存的 checkpoint 包含了生成它们的完整 workflow，因此它们可以像图像一样被加载到用户界面中，以获取用于创建它们的完整 workflow。</p>
<p>这个示例展示了如何使用简单的块合并来合并三个不同的 checkpoint ，其中 unet 的输入块、中间块和输出块可以有不同的比值：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_3_checkpoints.png" alt="Example"></p>
<p>因为 Lora 是一个模型在权重方面的补丁，因此它也可以 merge 到模型中。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_lora.png" alt="Example"></p>
<p>你也可以像这个示例一样，减去模型的权重并添加到 merge 中，通常这是用来从非 inpaint 模型中创建一个 inpaint 模型，公式是：<code>(inpaint_model - base_model) * 1.0 + other_model</code>。如果你在其他 UI 中用过“Add Difference”这个功能，在 ComfyUI 中的就是这样实现的。<img src="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_inpaint.png" alt="Example"></p>
<p>有件重要的事情需要注意，模型的合并保存，一般会用你硬件上推理用而设置的精度，也就是 16位浮点数，如果你想以 32 位浮点数进行合并，请使用以下命令启动 ComfyUI：<code>--force-fp32</code></p>
<h3 id="Advanced-Merging"><a href="#Advanced-Merging" class="headerlink" title="Advanced Merging"></a>Advanced Merging</h3><h4 id="CosXL"><a href="#CosXL" class="headerlink" title="CosXL"></a>CosXL</h4><p>这里是一个如何通过合并从<a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/sd_xl_base_1.0_0.9vae.safetensors">常规 SDXL 模型</a>创建 <a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/cosxl">CosXL 模型</a>的示例。所需的是 CosXL 基础模型、SDXL 基础模型以及你想要转换的 SDXL 模型。在这个示例中，我使用了<a target="_blank" rel="noopener" href="https://civitai.com/models/140737/albedobase-xl">albedobase-xl</a>。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/model_merging/model_merging_cosxl.png" alt="Example"></p>
<h2 id="15-3D-Examples"><a href="#15-3D-Examples" class="headerlink" title="15. 3D Examples"></a>15. 3D Examples</h2><h3 id="Stable-Zero123"><a href="#Stable-Zero123" class="headerlink" title="Stable Zero123"></a>Stable Zero123</h3><p>Stable Zero123 模型能够根据带有物体和简单背景的图像，生成该物体从不同角度的图像。</p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-zero123/blob/main/stable_zero123.ckpt">下载模型</a>后把它放在 ComfyUI/models/checkpoints 文件夹。</p>
<p>你可以下载下面这张图然后把它放在 ComfyUI 中来获得完整的 workflow。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/3d/stable_zero123_example.png" alt="Example"></p>
<p>输入图像可以在<a target="_blank" rel="noopener" href="https://comfyanonymous.github.io/ComfyUI_examples/hypernetworks/hypernetwork_example_output.png">这里</a>找到，它是来自 hypernetworks example 的输出图像。</p>
<p>Elevation（俯仰角）和 azimuth（方位角） 以度为单位，用来控制物体的旋转。</p>
<h2 id="16-LCM-Examples"><a href="#16-LCM-Examples" class="headerlink" title="16. LCM Examples"></a>16. LCM Examples</h2><p>LCM 是被设计成用少量步骤进行采样的模型。</p>
<p>LCM Loras 可以用来将普通模型转换成 LCM 模型</p>
<p>LCM SDXL lora 可以在<a target="_blank" rel="noopener" href="https://huggingface.co/latent-consistency/lcm-lora-sdxl/blob/main/pytorch_lora_weights.safetensors">这里</a>下载到</p>
<p>下载后重命名成 lcm_lora_sdxl.safetensors ，然后放在 ComfyUI/models/loras 目录下。</p>
<p>然后你可以在 ComfyUI 中加载这种图像来查看将 LCM SDXL lora 和 SDXL 基础模型一起使用的 workflow：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/lcm/lcm_basic_example.png" alt="Example"></p>
<p>需要注意要使用比较低的 cfg 值，使用 “lcm” 采样器，以及”sgm_uniform”或”simple”调度器。带有 lcm 设置的 ModelSamplingDiscrete 节点也会稍微改善效果，虽然不是必要的，但也推荐使用。</p>
<p>其他的 LCM loras 也可以用相同的方式用在各自对应的模型上。</p>
<h2 id="17-SDXL-Turbo-Examples"><a href="#17-SDXL-Turbo-Examples" class="headerlink" title="17. SDXL Turbo Examples"></a>17. SDXL Turbo Examples</h2><p>SDXL Turbo 是 SDXL 模型的一种，可以在单步中生成 consistent 的图像。你可以用更多的步骤来增加生成的质量。比如用新的 SDTurboScheduler 节点效果会比较好，但是常规的调度器也行。</p>
<p>这是下载<a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/sdxl-turbo/blob/main/sd_xl_turbo_1.0_fp16.safetensors">官方 SDXL turbo 模型</a>的地址</p>
<p>这是用对应的 workflow 生成的图片：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/sdxlturbo_example.png" alt="Example"></p>
<p>把这张图像保存下来并拖到 ComfyUI 上来查看完整的 workflow。然后我推荐在界面中启用 Extra Options -&gt; Auto Queue。然后点击 “Queue Prompt” 并开始编写你的 prompt。</p>
<h2 id="18-Stable-Cascade-Examples"><a href="#18-Stable-Cascade-Examples" class="headerlink" title="18. Stable Cascade Examples"></a>18. Stable Cascade Examples</h2><p>首先下载 <a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-cascade/tree/main/comfyui_checkpoints">stable_cascade_stage_c.safetensors 和 stable_cascade_stage_b.safetensors checkpoints</a> 放到 ComfyUI/models/checkpoints 文件夹中。</p>
<p>Stable cascade 是一个有三个阶段的处理流程，首先是用 C 阶段扩散模型生成低分辨率的 latent 图像。然后在 B 阶段扩散模型中放大它。放大后的图像再次放大后，通过 A 阶段的 VAE 转换成像素图片。</p>
<p>你可以下载本页面中的所有图像，然后加载或拖到 ComfyUI 上来查看完整的工作流程。</p>
<h3 id="Text-to-image"><a href="#Text-to-image" class="headerlink" title="Text to image"></a>Text to image</h3><p>这是一个基础的文生图 workflow</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__text_to_image.png" alt="Example"></p>
<h3 id="Image-to-Image"><a href="#Image-to-Image" class="headerlink" title="Image to Image"></a>Image to Image</h3><p>这里是一个基础图生图的例子，通过编码图片然后传给阶段 C 来实现。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__image_to_image.png" alt="Example"></p>
<h3 id="Image-Variations"><a href="#Image-Variations" class="headerlink" title="Image Variations"></a>Image Variations</h3><p>Stable Cascade 支持使用 CLIP vision 输出来创建图像的变体。请参考以下示例工作流程：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__image_remixing.png" alt="Example"></p>
<p>下面这个工作流展示了应该如何把多张图片混合到一起：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__image_remixing_multiple.png" alt="Example"></p>
<p>你可以在 <a target="_blank" rel="noopener" href="https://comfyanonymous.github.io/ComfyUI_examples/unclip">unCLIP example page</a> 找到用来输入的图片。</p>
<h3 id="ControlNet"><a href="#ControlNet" class="headerlink" title="ControlNet"></a>ControlNet</h3><p>你可以从<a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-cascade/tree/main/controlnet">这里</a>下载 stable cascade 用的 controlnet。在这些示例中，我通过在文件名前添加stable_cascade_来重命名文件，例如：stable_cascade_canny.safetensors、stable_cascade_inpainting.safetensors</p>
<p>下面是一个如何使用 Canny Controlnet 的示例：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__canny_controlnet.png" alt="Example"></p>
<p>下面是一个如何使用 Inpaint Controlnet 的示例，示例输入图像可以在<a target="_blank" rel="noopener" href="https://comfyanonymous.github.io/ComfyUI_examples/inpaint/yosemite_inpaint_example.png">这里</a>找到。你还可以在 LoadImage 节点中右键点击图像，并使用遮罩编辑器对其进行编辑。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/stable_cascade__inpaint_controlnet.png" alt="Example"></p>
<h2 id="19-Image-Edit-Model-Examples"><a href="#19-Image-Edit-Model-Examples" class="headerlink" title="19. Image Edit Model Examples"></a>19. Image Edit Model Examples</h2><p>Edit 模型，也成为 InstructPix2Pix 模型，是可以通过文本提示编辑图像的模型。</p>
<p>这是 SDXL Edit 模型的 workflow，可以在这里<a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/cosxl">下载</a>模型。下载 cosxl_edit.safetensors 文件后，将其放在 ComfyUI/models/checkpoints 文件夹中来使用它。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/edit_models/sdxl_edit_model.png" alt="Example"></p>
<p>把这张图像保存下来并拖到 ComfyUI 上来查看完整的 workflow。</p>
<p>上述示例中使用的输入图像可以在<a target="_blank" rel="noopener" href="https://comfyanonymous.github.io/ComfyUI_examples/unclip/mountains.png">这里</a>下载。</p>
<h2 id="20-Video-Examples"><a href="#20-Video-Examples" class="headerlink" title="20. Video Examples"></a>20. Video Examples</h2><h3 id="Image-to-Video"><a href="#Image-to-Video" class="headerlink" title="Image to Video"></a>Image to Video</h3><p>目前有两个将图片转换成视频的模型。<a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-video-diffusion-img2vid/blob/main/svd.safetensors">the one tuned to generate 14 frame videos</a> 和 <a target="_blank" rel="noopener" href="https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt/blob/main/svd_xt.safetensors">the one for 25 frame videos</a>。下载后放在 ComfyUI/models/checkpoints 文件夹中。</p>
<p>最基础的使用图生视频功能的方式是，输入一张初始图片——就和下面的这张一样——然后使用 14 frame 模型。你可以下载这张 webp 格式的动画图片，然后加载或直接拖到 ComfyUI 中来查看完整的 workflow。</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/video/image_to_video.webp" alt="Example"></p>
<p><a target="_blank" rel="noopener" href="https://comfyanonymous.github.io/ComfyUI_examples/video/workflow_image_to_video.json">Json 格式的 workflow</a></p>
<p>你可以在 <a target="_blank" rel="noopener" href="https://comfyanonymous.github.io/ComfyUI_examples/unclip">unCLIP example page</a> 里找到输入图片。</p>
<p>你也可以在下面这个 workflow 里使用这个功能，它用 SDXL 模型来生成一张初始图片，然后传递给 25 frame videos：</p>
<p><img src="https://comfyanonymous.github.io/ComfyUI_examples/video/txt_to_image_to_video.webp" alt="Example"></p>
<p><a target="_blank" rel="noopener" href="https://comfyanonymous.github.io/ComfyUI_examples/video/workflow_txt_to_img_to_video.json">Json 格式的 workflow</a></p>
<p>关于参数的一些解释：</p>
<p>video_frames：要生成的视频帧数。</p>
<p>motion_bucket_id：该数字越高，视频中的动态部分越多。</p>
<p>fps：帧率越高，视频越流畅。</p>
<p>augmentation level：添加到初始图片的噪点数量，该值越高，视频与初始图片的相似度越低。增加该值可获得更多的动态效果。</p>
<p>VideoLinearCFGGuidance：这个节点稍微改善了这些视频模型的采样效果，它的作用是在不同帧之间线性缩放 cfg。在上述示例中，第一帧的 cfg 为 1.0（节点中的 min_cfg），中间帧为 1.75，最后一帧为 2.5（采样器中设置的 cfg）。这样，离初始帧较远的帧将逐渐获得更高的 cfg。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>ComfyUI_examples 翻译笔记</p><p><a href="http://xuweinan.com/2024/05/02/ComfyUI-examples-翻译笔记/">http://xuweinan.com/2024/05/02/ComfyUI-examples-翻译笔记/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>徐炜楠</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-05-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2024-05-02</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E9%9A%8F%E7%AC%94/">随笔</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/09/07/%E5%BE%AE%E4%BF%A1%E2%9D%8C-%E8%8B%B9%E6%9E%9C%E2%9C%85-%E8%8B%B9%E6%9E%9C%E7%A8%8E%E2%9D%8C/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">微信❌ 苹果✅ 苹果税❌</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/09/13/GPT-%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7-%E9%9A%90%E7%A7%81%E6%94%BF%E7%AD%96/"><span class="level-item">GPT 调试工具 隐私政策</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="徐炜楠"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">徐炜楠</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>深圳</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">102</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">45</p></a></div></div></nav></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/XuWeinan123" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="https://space.bilibili.com/18601263" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bilibili</span></span><span class="level-right"><span class="level-item tag">space.bilibili.com</span></span></a></li><li><a class="level is-mobile" href="https://dribbble.com/woshixwn" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Dribbble</span></span><span class="level-right"><span class="level-item tag">dribbble.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E4%BD%9C%E5%93%81%E9%9B%86/"><span class="level-start"><span class="level-item">作品集</span></span><span class="level-end"><span class="level-item tag">35</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%AE%9E%E4%B9%A0%E6%97%A5%E5%BF%97/"><span class="level-start"><span class="level-item">实习日志</span></span><span class="level-end"><span class="level-item tag">26</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%99%E7%A8%8B/"><span class="level-start"><span class="level-item">教程</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"><span class="level-start"><span class="level-item">未分类</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%82%9C%E5%93%A5%E7%9A%84%E7%A0%94%E7%A9%B6%E7%AC%94%E8%AE%B0/"><span class="level-start"><span class="level-item">炜哥的研究笔记</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%A7%86%E9%A2%91%E4%BD%9C%E5%93%81/"><span class="level-start"><span class="level-item">视频作品</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E9%9A%8F%E7%AC%94/"><span class="level-start"><span class="level-item">随笔</span></span><span class="level-end"><span class="level-item tag">28</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2026-01-31T06:07:40.000Z">2026-01-31</time></p><p class="title"><a href="/2026/01/31/%E3%80%90%E6%BC%AB%E7%94%BB%E6%8E%A8%E8%8D%90%E3%80%91%E7%AA%81%E7%84%B6%E7%9C%8B%E6%87%82%E4%BA%86%E3%80%8A%E5%86%8D%E8%A7%81%E7%BB%98%E6%A2%A8%E3%80%8B/">【漫画推荐】突然看懂了《再见绘梨》</a></p><p class="categories"><a href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2026-01-17T07:00:00.000Z">2026-01-17</time></p><p class="title"><a href="/2026/01/17/%E8%BF%99%E4%BA%9B%E7%BD%91%E7%AB%99%E5%B8%AE%E6%88%91%E5%AE%9E%E7%8E%B0%E4%BA%86%E6%BC%AB%E7%94%BB%E8%87%AA%E7%94%B1/">这些网站帮我实现了漫画自由</a></p><p class="categories"><a href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-02T11:18:00.000Z">2025-04-02</time></p><p class="title"><a href="/2025/04/02/MGX-%E5%8A%9F%E8%83%BD%E4%BD%93%E9%AA%8C%E5%88%86%E6%9E%90/">MGX 功能体验分析</a></p><p class="categories"><a href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-31T15:24:16.000Z">2025-03-31</time></p><p class="title"><a href="/2025/03/31/Comic-Manga-Privacy-Policy/">Comic&amp;Manga Privacy Policy</a></p><p class="categories"><a href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-03-26T09:12:51.000Z">2025-03-26</time></p><p class="title"><a href="/2025/03/26/Comic-Folder-s-Structure/">Comic Folder&#039;s Structure</a></p><p class="categories"><a href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AE/"><span class="tag">AE</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/APP%E6%9E%84%E6%80%9D/"><span class="tag">APP构思</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Android%E5%BA%94%E7%94%A8/"><span class="tag">Android应用</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Blender/"><span class="tag">Blender</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dian/"><span class="tag">Dian</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MG%E5%8A%A8%E7%94%BB/"><span class="tag">MG动画</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VLOG/"><span class="tag">VLOG</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vfun/"><span class="tag">vfun</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%89%E6%98%9F/"><span class="tag">三星</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%92%E8%81%94%E7%BD%91%E8%A7%82%E5%AF%9F/"><span class="tag">互联网观察</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%A4%E4%BA%92%E8%AE%BE%E8%AE%A1/"><span class="tag">交互设计</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%A7%E5%93%81/"><span class="tag">产品</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BB%A3%E7%A0%81/"><span class="tag">代码</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BD%9C%E5%93%81%E9%9B%86/"><span class="tag">作品集</span><span class="tag">35</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%85%A8%E6%A0%88%E8%AE%BE%E8%AE%A1%E5%B8%88/"><span class="tag">全栈设计师</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%86%99%E7%BB%99%E8%AE%BE%E8%AE%A1%E5%B8%88%E7%9A%84%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86/"><span class="tag">写给设计师的开发知识</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%9B%E6%84%8F/"><span class="tag">创意</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%B0-2023-%E5%B9%B4%E4%B8%BA%E6%AD%A2%E7%9A%84%E6%89%8B%E6%9C%BA%E6%95%85%E4%BA%8B/"><span class="tag">到 2023 年为止的手机故事</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%95%88/"><span class="tag">动效</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%95%88%E8%AE%BE%E8%AE%A1/"><span class="tag">动效设计</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%8E%E4%B8%AD%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6/"><span class="tag">华中科技大学</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8D%A1%E9%A1%BF/"><span class="tag">卡顿</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E5%B9%BF%E8%B5%9B/"><span class="tag">大广赛</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%9E%E4%B9%A0%E6%97%A5%E5%BF%97/"><span class="tag">实习日志</span><span class="tag">27</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%A3%E4%BC%A0%E9%83%A8/"><span class="tag">宣传部</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B0%8F%E7%B1%B3/"><span class="tag">小米</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B8%83%E5%B1%80%E4%B8%8E%E8%87%AA%E9%80%82%E5%BA%94/"><span class="tag">布局与自适应</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B9%B3%E9%9D%A2%E8%AE%BE%E8%AE%A1/"><span class="tag">平面设计</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B9%BF%E5%91%8A/"><span class="tag">广告</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%89%BE%E5%B7%A5%E4%BD%9C/"><span class="tag">找工作</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%90%AC%E8%BF%90%E8%87%AAWordPress/"><span class="tag">搬运自WordPress</span><span class="tag">33</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%99%E7%A8%8B/"><span class="tag">教程</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B5%B7%E6%8A%A5/"><span class="tag">海报</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B8%B8%E6%88%8F/"><span class="tag">游戏</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%88%AC%E8%99%AB/"><span class="tag">爬虫</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A1%95%E5%B8%82%E7%94%9F/"><span class="tag">硕市生</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%8B%E6%8B%9B%E7%AC%94%E8%AF%95/"><span class="tag">秋招笔试</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%A7%86%E9%A2%91%E4%BD%9C%E5%93%81/"><span class="tag">视频作品</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BE%E8%AE%A1/"><span class="tag">设计</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%84%E6%B5%8B/"><span class="tag">评测</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B0%83%E7%A0%94%E6%95%B0%E6%8D%AE/"><span class="tag">调研数据</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/"><span class="tag">软件推荐</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BF%90%E8%90%A5/"><span class="tag">运营</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔</span><span class="tag">55</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E8%AF%95%E7%BB%8F%E5%8E%86/"><span class="tag">面试经历</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">XUWEINAN</a><p class="is-size-7"><span>&copy; 2026 徐炜楠</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>